{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Define the column names\n",
    "    column_names = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
    "\n",
    "    # Load the data and add column names\n",
    "    data = pd.read_csv('data/nursery.data', delimiter=',', names=column_names)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (12960, 9)\n",
      "  parents has_nurs      form children     housing     finance         social       health       class\n",
      "0   usual   proper  complete        1  convenient  convenient        nonprob  recommended   recommend\n",
      "1   usual   proper  complete        1  convenient  convenient        nonprob     priority    priority\n",
      "2   usual   proper  complete        1  convenient  convenient        nonprob    not_recom   not_recom\n",
      "3   usual   proper  complete        1  convenient  convenient  slightly_prob  recommended   recommend\n",
      "4   usual   proper  complete        1  convenient  convenient  slightly_prob     priority    priority\n",
      "5   usual   proper  complete        1  convenient  convenient  slightly_prob    not_recom   not_recom\n",
      "6   usual   proper  complete        1  convenient  convenient    problematic  recommended    priority\n",
      "7   usual   proper  complete        1  convenient  convenient    problematic     priority    priority\n",
      "8   usual   proper  complete        1  convenient  convenient    problematic    not_recom   not_recom\n",
      "9   usual   proper  complete        1  convenient      inconv        nonprob  recommended  very_recom \n",
      "\n",
      "       parents has_nurs      form children     housing     finance   social       health      class\n",
      "count    12960    12960     12960    12960       12960       12960    12960        12960      12960\n",
      "unique       3        5         4        4           3           2        3            3          5\n",
      "top      usual   proper  complete        1  convenient  convenient  nonprob  recommended  not_recom\n",
      "freq      4320     2592      3240     3240        4320        6480     4320         4320       4320 \n",
      "\n",
      "parents     0\n",
      "has_nurs    0\n",
      "form        0\n",
      "children    0\n",
      "housing     0\n",
      "finance     0\n",
      "social      0\n",
      "health      0\n",
      "class       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"Data Shape: \", data.shape)\n",
    "\n",
    "# Print the first 10 rows\n",
    "print(data.head(10).to_string(), \"\\n\")\n",
    "\n",
    "# Get information about the data\n",
    "print(data.describe().to_string(), \"\\n\")\n",
    "\n",
    "# Check if there are missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    # Separate the features and target variable before encoding\n",
    "    X = data.drop('class', axis=1)\n",
    "    y = data['class']\n",
    "\n",
    "    X_encoded = pd.get_dummies(X)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = tts(X_encoded, y, test_size=0.2, random_state=13)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X_encoded, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(criteria, X_train, y_train):\n",
    "    # Train the model with criteria\n",
    "    model = DecisionTreeClassifier(criterion=criteria, random_state=13, max_depth=3, min_samples_leaf=3)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test):\n",
    "    # Predict the target variable\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, confusion, classification_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index\n",
      "Prediction:  ['spec_prior' 'priority' 'priority' ... 'priority' 'spec_prior'\n",
      " 'not_recom']\n",
      "Confusion Matrix: \n",
      " [[825   0   0   0   0]\n",
      " [  0 739   0 133   0]\n",
      " [  0   1   0   0   0]\n",
      " [  0 267   0 557   0]\n",
      " [  0  70   0   0   0]]\n",
      "Accuracy:  0.8182870370370371\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   not_recom       1.00      1.00      1.00       825\n",
      "    priority       0.69      0.85      0.76       872\n",
      "   recommend       0.00      0.00      0.00         1\n",
      "  spec_prior       0.81      0.68      0.74       824\n",
      "  very_recom       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.82      2592\n",
      "   macro avg       0.50      0.50      0.50      2592\n",
      "weighted avg       0.81      0.82      0.81      2592\n",
      "\n",
      "Entropy\n",
      "Prediction:  ['priority' 'priority' 'priority' ... 'spec_prior' 'spec_prior'\n",
      " 'not_recom']\n",
      "Confusion Matrix: \n",
      " [[825   0   0   0   0]\n",
      " [  0 663   0 209   0]\n",
      " [  0   1   0   0   0]\n",
      " [  0 209   0 615   0]\n",
      " [  0  70   0   0   0]]\n",
      "Accuracy:  0.8113425925925926\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   not_recom       1.00      1.00      1.00       825\n",
      "    priority       0.70      0.76      0.73       872\n",
      "   recommend       0.00      0.00      0.00         1\n",
      "  spec_prior       0.75      0.75      0.75       824\n",
      "  very_recom       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.81      2592\n",
      "   macro avg       0.49      0.50      0.50      2592\n",
      "weighted avg       0.79      0.81      0.80      2592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index\n",
      "Best parameters:  {'max_depth': 3, 'min_samples_leaf': 3}\n",
      "Best score:  0.6900462962962963\n",
      "Cross-validation scores:  [0.68171296 0.70138889 0.7349537  0.6867284  0.64544753]\n",
      "Average cross-validation score:  0.6900462962962963\n",
      "Entropy\n",
      "Best parameters:  {'max_depth': 5, 'min_samples_leaf': 7}\n",
      "Best score:  0.687577160493827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "d:\\User\\Documents\\MasterProjects\\KDDM-PosterWorkshop\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.68171296 0.78433642 0.53819444 0.77314815 0.66049383]\n",
      "Average cross-validation score:  0.687577160493827\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, X_encoded, y = split_data(data)\n",
    "\n",
    "    # Train the model with gini\n",
    "    gini_model = training(\"gini\", X_train, y_train)\n",
    "\n",
    "    # Train the model with entropy\n",
    "    entropy_model = training(\"entropy\", X_train, y_train)\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    y_pred_gini = predict(gini_model, X_test)\n",
    "    accuracy_gini, confusion_gini, classification_gini = evaluate(y_test, y_pred_gini)\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    y_pred_entropy = predict(entropy_model, X_test)\n",
    "    accuracy_entropy, confusion_entropy, classification_entropy = evaluate(y_test, y_pred_entropy)\n",
    "\n",
    "    # Prints\n",
    "    print(\"Gini Index\")\n",
    "    print(\"Prediction: \", y_pred_gini)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_gini)\n",
    "    print(\"Accuracy: \", accuracy_gini)\n",
    "    print(\"Classification Report: \\n\", classification_gini)\n",
    "\n",
    "    # Prints\n",
    "    print(\"Entropy\")\n",
    "    print(\"Prediction: \", y_pred_entropy)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_entropy)\n",
    "    print(\"Accuracy: \", accuracy_entropy)\n",
    "    print(\"Classification Report: \\n\", classification_entropy)\n",
    "\n",
    "    # Grid search\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_samples_leaf': [3, 5, 7, 10],\n",
    "    }\n",
    "\n",
    "    grid_search_gini = GridSearchCV(gini_model, param_grid, cv=5)\n",
    "    grid_search_gini.fit(X_encoded, y)\n",
    "\n",
    "    grid_search_entropy = GridSearchCV(entropy_model, param_grid, cv=5)\n",
    "    grid_search_entropy.fit(X_encoded, y)\n",
    "\n",
    "    # Print best parameters and score\n",
    "    print(\"Gini Index\")\n",
    "    print(\"Best parameters: \", grid_search_gini.best_params_)\n",
    "    print(\"Best score: \", grid_search_gini.best_score_)\n",
    "\n",
    "    # Perform cross-validation with best model\n",
    "    best_model = grid_search_gini.best_estimator_\n",
    "    scores = cross_val_score(best_model, X_encoded, y, cv=5)\n",
    "\n",
    "    print(\"Cross-validation scores: \", scores)\n",
    "    print(\"Average cross-validation score: \", scores.mean())\n",
    "\n",
    "    # Print best parameters and score\n",
    "    print(\"Entropy\")\n",
    "    print(\"Best parameters: \", grid_search_entropy.best_params_)\n",
    "    print(\"Best score: \", grid_search_entropy.best_score_)\n",
    "\n",
    "    # Perform cross-validation with best model\n",
    "    best_model2 = grid_search_entropy.best_estimator_\n",
    "    scores2 = cross_val_score(best_model2, X_encoded, y, cv=5)\n",
    "\n",
    "    print(\"Cross-validation scores: \", scores2)\n",
    "    print(\"Average cross-validation score: \", scores2.mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
